# Semantic Search Engine with FAISS

This project implements a Semantic Search Engine that retrieves text results based on meaning and context rather than exact keyword matching.
It uses Sentence Transformers for embedding generation and FAISS for fast similarity search, with a simple and interactive Streamlit UI.



## ğŸš€ Features

- Semantic similarity search using dense embeddings
- Fast Approximate Nearest Neighbor (ANN) search with FAISS
- Clean Streamlit-based web interface
- Displays top-k relevant results with similarity scores
- Efficient indexing and low query latency


#  Project Structure

```
semantic-search-faiss/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ embed.py            # Generate sentence embeddings
â”‚   â”œâ”€â”€ build_index.py      # Build FAISS index
â”‚   â”œâ”€â”€ search.py           # Query FAISS index
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ tweets.csv          # Raw dataset
â”‚   â”œâ”€â”€ texts.csv           # Cleaned text data
â”‚   â”œâ”€â”€ embeddings.npy      # Generated embeddings (ignored in git)
â”‚   â””â”€â”€ faiss.index         # FAISS index file (ignored in git)
â”‚
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ app.py              # Streamlit UI
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md



#  Technologies Used

- Python 3.x
- sentence-transformers
- FAISS
- Pandas & NumPy
- Streamlit


#  Setup Instructions

# 1ï¸ Clone the Repository

```bash
git clone https://github.com/shajiashireen/semantic-search-faiss.git
cd semantic-search-faiss
```



# 2ï¸ Install Dependencies

```bash
pip install -r requirements.txt
```

---

#  How to Run the Project

# Step 1: Generate Sentence Embeddings

```bash
python backend/embed.py
```

---

# Step 2: Build FAISS Index

```bash
python backend/build_index.py
```

---

# Step 3: Launch the Web Interface

```bash
streamlit run ui/app.py
```

---

#  Example Queries

- happy
- feeling tired today
- missing my friends
- need motivation

---

#  Performance Metrics

| Metric | Value |
|------|------|
| Dataset Size | 5,000 text snippets |
| Embedding Model | all-MiniLM-L6-v2 |
| Index Type | FAISS IVF |
| Indexing Time | ~1â€“2 seconds |
| Average Query Latency | ~3â€“6 ms |



#  How It Works

1. Text data is converted into numerical embeddings using a pretrained transformer model.
2. These embeddings are indexed using FAISS for fast similarity search.
3. User queries are embedded and compared against the index.
4. The most semantically similar results are returned with a similarity score.


#  Notes

- Semantic search focuses on context and meaning, not exact keywords.
- Similarity scores represent semantic closeness.

